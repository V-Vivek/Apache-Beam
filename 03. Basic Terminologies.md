## Basic Terminologies in Apache Beam

Understanding the basic terminologies in Apache Beam is crucial for effectively building and managing data processing pipelines. Here are some key terms:

### 1. Pipeline

A **Pipeline** represents the entire data processing workflow in Apache Beam. It consists of a series of transformations that process input data and produce output data. The pipeline definition is independent of the runtime environment, allowing it to be executed on different runners.

### 2. PCollection

- A **PCollection** (parallel collection) is a distributed data set that serves as the input and output for each step in a pipeline. PCollections can contain bounded (batch) or unbounded (streaming) data.
- **Immutability** - PCollections are immutable. Applying transformation on a PCollection results in creation of a new PCollection.
- **Element Type** - The elements in a PCollecetion may be of any type, but all must be of the same type.
- **Operation Type** - PCollection does not support grained operations. We cannot apply transformations on some specific elements in a PCollection. 
- **TimeStamps** - Each element in a PCollection has a associated timestamp with it.
    - Unbounded PCollections - Source assign the timestamps.
    - Bounded PCollections - Every element is set to same timestamp.

  
### 3. PTransform

A PTransform (or transform) represents a data processing operation, or a step, in your pipeline. A transform is applied to zero or more PCollection objects, and produces zero or more PCollection objects.

### 4. ParDo

**ParDo** is a core transform in Apache Beam used for parallel processing. It applies a user-defined function (DoFn) to each element in the input PCollection, producing zero or more output elements. ParDo is used for tasks such as filtering, mapping, and flat-mapping.

### 5. DoFn

A **DoFn** (Do Function) is a user-defined function applied to each element in a PCollection by a ParDo transform. It contains the processing logic for transforming input elements to output elements.

### 6. GroupByKey

**GroupByKey** is a transform that groups elements in a PCollection by their key. It is often used in combination with the `ParDo` transform to perform operations on grouped data, such as aggregation or sorting.

### 7. Aggregation
Aggregation is computing a value from multiple (1 or more) input elements.

### 8. Windowing

**Windowing** is a mechanism for subdividing a PCollection into logical windows based on event time. It is essential for processing unbounded (streaming) data. Common windowing strategies include:

- **Fixed Windows**: Divides data into fixed-size, non-overlapping windows.
- **Sliding Windows**: Creates overlapping windows with a fixed size and a sliding interval.
- **Session Windows**: Groups data into sessions based on periods of inactivity.

### 9. Watermark
- A watermark is a guess as to when all data in a certain window is expected to have arrived.
- This is needed because data isnâ€™t always guaranteed to arrive in a pipeline in time order, or to always arrive at predictable intervals.

### 10. Triggers

**Triggers** determine when to emit the results of a windowed computation. They control how and when window results are materialized. Common types of triggers include:

- **Event Time Triggers**: Trigger based on the event time of data elements.
- **Processing Time Triggers**: Trigger based on the processing time at the worker.
- **Composite Triggers**: Combine multiple trigger conditions.

### 11. I/O Connectors

**I/O Connectors** are used to read from and write to various data sources and sinks. Apache Beam provides connectors for different storage systems, databases, and messaging systems, such as Google Cloud Storage, Apache Kafka, and BigQuery.

### 12. Runner

A **Runner** is an execution engine that runs Beam pipelines. It translates the pipeline into a series of operations that can be executed on a specific data processing system. Popular runners include Apache Flink, Apache Spark, and Google Cloud Dataflow.

### 13. User-defined function (UDF)
Some Beam operations allow you to run user-defined code as a way to configure the transform.

### Conclusion

These basic terminologies form the foundation of understanding Apache Beam. Familiarity with these terms is essential for building effective and efficient data processing pipelines.
