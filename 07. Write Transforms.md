## Write Transforms in Apache Beam

Apache Beam provides several write transforms to output data to various sinks. Each transform is designed to handle different data formats and storage systems, allowing flexibility in data output options.

### 1. WriteToText

Writes data to a text file, where each element in the PCollection is written as a single line.

**Parameters**:
- `file_path_prefix`: (Required) The file path prefix for the output files. Beam appends unique suffixes to each file.
- `file_name_suffix`: (Optional) The file name suffix to use for the output files (e.g., `.txt`).
- `append_trailing_newlines`: (Optional) Whether to append a newline to each element (default is `True`).
- `num_shards`: (Optional) The number of output shards (files) to write. If not set, Beam determines the number automatically. It is recommend to not set this so that beam can dynamically decide it based on size of data.
- `shard_name_template`: (Optional) A template string for naming output files.
- `compression_type`: (Optional) The compression type for the output files, such as `UNCOMPRESSED`, `GZIP`, or `BZIP2`.
- `header`: Specifies the Header line of the Output file.

**Example**:
```python
import apache_beam as beam

def run():
    with beam.Pipeline() as pipeline:
        data = ['apple', 'banana', 'cherry']
        pcollection = pipeline | 'Create' >> beam.Create(data)
        pcollection | 'WriteToText' >> beam.io.WriteToText('output', file_name_suffix='.txt')

if __name__ == '__main__':
    run()
# Output file -> output-00000-of-00001.txt
# prefix -> output
# shard identifier -> 00000-of-00001
# suffix -> .txt
```

### 2. WriteToAvro
Writes data to Avro files.

**Parameters**:

- `file_path_prefix`: (Required) The file path prefix for the output files.
- `schema`: (Required) The Avro schema to use for encoding the data.
- `file_name_suffix`: (Optional) The file name suffix for the output files (default is .avro).
- `codec`: (Optional) The codec to use for compression (default is deflate).
- `num_shards`: (Optional) The number of output shards (files) to write.
- `use_fastavro`: When set to TRUE, uses the 'fastavro' library to write the Avro file.

**Example**:
```python
import apache_beam as beam
from apache_beam.io.avroio import WriteToAvro

def run():
    with beam.Pipeline() as pipeline:
        schema = {
            "type": "record",
            "name": "Fruit",
            "fields": [
                {"name": "name", "type": "string"},
                {"name": "quantity", "type": "int"}
            ]
        }
        data = [{'name': 'apple', 'quantity': 10}, {'name': 'banana', 'quantity': 20}]
        pcollection = pipeline | 'Create' >> beam.Create(data)
        pcollection | 'WriteToAvro' >> WriteToAvro('output', schema=schema)

if __name__ == '__main__':
    run()
```
